2024-10-09 15:20:16,221 Training process is started.
python "C:\Users\DS1DPC2003M\Desktop\tool\neural_network_console3.10\libs\Python\Lib\site-packages\nnabla\utils\cli\cli.py" train
	-c "C:\Users\DS1DPC2003M\Desktop\spresense_cv\data_set\foopinmodel56x56.files\20241009_152016\net.nntxt"
	-o "C:\Users\DS1DPC2003M\Desktop\spresense_cv\data_set\foopinmodel56x56.files\20241009_152016"
2024-10-09 15:20:17,480 [nnabla]: [CALLBACK]: Exec train on local
2024-10-09 15:20:17,492 [nnabla]: Using context "Context(backend=['cpu:float'], array_class='CpuCachedArray', device_id='')"
2024-10-09 15:20:17,492 [nnabla]: Creating cache data for "C:\Users\DS1DPC2003M\Desktop\spresense_cv\dataset3\train.csv"
2024-10-09 15:20:17,550 [nnabla]: Creating cache data for "C:\Users\DS1DPC2003M\Desktop\spresense_cv\dataset3\test.csv"
2024-10-09 15:20:17,591 [nnabla]: Train with contexts ['cpu']
2024-10-09 15:20:17,607 [nnabla]: Training epoch 1 of 300 begin
2024-10-09 15:20:17,607 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-10-09 15:20:17,607 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-10-09 15:20:18,385 [nnabla]: epoch 1 of 300 cost=0.830461  {train_error=0.750806, valid_error=0.764628} time=(0.5s /145.8s) 
2024-10-09 15:20:18,951 [nnabla]: epoch 2 of 300 cost=0.720777  {train_error=0.698373, valid_error=0.719092} time=(1.1s /163.1s) 
2024-10-09 15:20:19,505 [nnabla]: epoch 3 of 300 cost=0.679257  {train_error=0.627047, valid_error=0.632649} time=(1.6s /164.7s) 
2024-10-09 15:20:20,071 [nnabla]: epoch 4 of 300 cost=0.621380  {train_error=0.540031, valid_error=0.555827} time=(2.2s /165.2s) 
2024-10-09 15:20:20,737 [nnabla]: epoch 5 of 300 cost=0.565761  {train_error=0.507615, valid_error=0.519426} time=(2.8s /166.1s) 
2024-10-09 15:20:21,110 [nnabla]: epoch 6 of 300 cost=0.524116  time=(3.5s /175.1s) 
2024-10-09 15:20:21,428 [nnabla]: epoch 7 of 300 cost=0.490496  time=(3.8s /163.7s) 
2024-10-09 15:20:21,896 [nnabla]: epoch 8 of 300 cost=0.488889  time=(4.3s /160.7s) 
2024-10-09 15:20:22,208 [nnabla]: epoch 9 of 300 cost=0.446751  time=(4.6s /153.3s) 
2024-10-09 15:20:22,781 [nnabla]: epoch 10 of 300 cost=0.382883  {train_error=0.323350, valid_error=0.348008} time=(4.9s /147.2s) 
2024-10-09 15:20:23,086 [nnabla]: epoch 11 of 300 cost=0.518786  time=(5.5s /149.4s) 
2024-10-09 15:20:23,402 [nnabla]: epoch 12 of 300 cost=0.468534  time=(5.8s /144.7s) 
2024-10-09 15:20:23,709 [nnabla]: epoch 13 of 300 cost=0.428855  time=(6.1s /140.8s) 
2024-10-09 15:20:24,014 [nnabla]: epoch 14 of 300 cost=0.381036  time=(6.4s /137.3s) 
2024-10-09 15:20:24,398 [nnabla]: epoch 15 of 300 cost=0.419700  time=(6.8s /135.8s) 
2024-10-09 15:20:24,787 [nnabla]: epoch 16 of 300 cost=0.380753  time=(7.2s /134.6s) 
2024-10-09 15:20:25,104 [nnabla]: epoch 17 of 300 cost=0.359825  time=(7.5s /132.3s) 
2024-10-09 15:20:25,411 [nnabla]: epoch 18 of 300 cost=0.356482  time=(7.8s /130.0s) 
2024-10-09 15:20:25,731 [nnabla]: epoch 19 of 300 cost=0.372774  time=(8.1s /128.3s) 
2024-10-09 15:20:26,331 [nnabla]: epoch 20 of 300 cost=0.310145  {train_error=0.178654, valid_error=0.290614} time=(8.4s /126.7s) 
2024-10-09 15:20:26,649 [nnabla]: epoch 21 of 300 cost=0.369427  time=(9.0s /129.1s) 
2024-10-09 15:20:26,971 [nnabla]: epoch 22 of 300 cost=0.341247  time=(9.4s /127.7s) 
2024-10-09 15:20:27,479 [nnabla]: epoch 23 of 300 cost=0.371657  time=(9.9s /128.6s) 
