2024-10-09 16:50:04,942 Training process is started.
python "C:\Users\DS1DPC2003M\Desktop\tool\neural_network_console3.10\libs\Python\Lib\site-packages\nnabla\utils\cli\cli.py" train
	-c "C:\Users\DS1DPC2003M\Desktop\spresense_cv\data_set\foopinmodel.files\20241009_165004\net.nntxt"
	-o "C:\Users\DS1DPC2003M\Desktop\spresense_cv\data_set\foopinmodel.files\20241009_165004"
2024-10-09 16:50:06,296 [nnabla]: [CALLBACK]: Exec train on local
2024-10-09 16:50:06,305 [nnabla]: Using context "Context(backend=['cpu:float'], array_class='CpuCachedArray', device_id='')"
2024-10-09 16:50:06,305 [nnabla]: Creating cache data for "C:\Users\DS1DPC2003M\Desktop\spresense_cv\dataset2\train.csv"
2024-10-09 16:50:06,366 [nnabla]: Creating cache data for "C:\Users\DS1DPC2003M\Desktop\spresense_cv\dataset2\test.csv"
2024-10-09 16:50:06,436 [nnabla]: Train with contexts ['cpu']
2024-10-09 16:50:06,463 [nnabla]: Training epoch 1 of 300 begin
2024-10-09 16:50:06,463 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-10-09 16:50:06,463 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-10-09 16:50:06,592 [nnabla]: epoch 1 of 300 cost=0.748348  {train_error=0.679423, valid_error=0.697614} time=(0.1s /21.9s) 
2024-10-09 16:50:06,672 [nnabla]: epoch 2 of 300 cost=0.714483  {train_error=0.674597, valid_error=0.689811} time=(0.2s /25.1s) 
2024-10-09 16:50:06,745 [nnabla]: epoch 3 of 300 cost=0.703795  {train_error=0.675580, valid_error=0.676777} time=(0.2s /24.7s) 
2024-10-09 16:50:06,815 [nnabla]: epoch 4 of 300 cost=0.690183  {train_error=0.664749, valid_error=0.679238} time=(0.3s /24.0s) 
2024-10-09 16:50:06,897 [nnabla]: epoch 5 of 300 cost=0.684078  {train_error=0.656766, valid_error=0.676105} time=(0.4s /23.4s) 
2024-10-09 16:50:06,940 [nnabla]: epoch 6 of 300 cost=0.696261  time=(0.5s /23.8s) 
2024-10-09 16:50:06,980 [nnabla]: epoch 7 of 300 cost=0.685782  time=(0.5s /22.2s) 
2024-10-09 16:50:07,021 [nnabla]: epoch 8 of 300 cost=0.680785  time=(0.6s /20.9s) 
2024-10-09 16:50:07,060 [nnabla]: epoch 9 of 300 cost=0.677981  time=(0.6s /19.9s) 
2024-10-09 16:50:07,143 [nnabla]: epoch 10 of 300 cost=0.673023  {train_error=0.639618, valid_error=0.649410} time=(0.6s /19.1s) 
2024-10-09 16:50:07,181 [nnabla]: epoch 11 of 300 cost=0.668645  time=(0.7s /19.6s) 
2024-10-09 16:50:07,223 [nnabla]: epoch 12 of 300 cost=0.668923  time=(0.8s /18.9s) 
2024-10-09 16:50:07,263 [nnabla]: epoch 13 of 300 cost=0.662666  time=(0.8s /18.5s) 
2024-10-09 16:50:07,306 [nnabla]: epoch 14 of 300 cost=0.662339  time=(0.8s /18.1s) 
2024-10-09 16:50:07,348 [nnabla]: epoch 15 of 300 cost=0.647654  time=(0.9s /17.7s) 
2024-10-09 16:50:07,388 [nnabla]: epoch 16 of 300 cost=0.643921  time=(0.9s /17.3s) 
2024-10-09 16:50:07,429 [nnabla]: epoch 17 of 300 cost=0.653984  time=(1.0s /17.0s) 
2024-10-09 16:50:07,469 [nnabla]: epoch 18 of 300 cost=0.658917  time=(1.0s /16.8s) 
2024-10-09 16:50:07,509 [nnabla]: epoch 19 of 300 cost=0.643854  time=(1.0s /16.5s) 
2024-10-09 16:50:07,594 [nnabla]: epoch 20 of 300 cost=0.640581  {train_error=0.602795, valid_error=0.612217} time=(1.1s /16.3s) 
2024-10-09 16:50:07,637 [nnabla]: epoch 21 of 300 cost=0.638797  time=(1.2s /16.8s) 
2024-10-09 16:50:07,675 [nnabla]: epoch 22 of 300 cost=0.631012  time=(1.2s /16.5s) 
