2024-10-09 16:55:12,243 Training process is started.
python "C:\Users\DS1DPC2003M\Desktop\tool\neural_network_console3.10\libs\Python\Lib\site-packages\nnabla\utils\cli\cli.py" train
	-c "C:\Users\DS1DPC2003M\Desktop\spresense_cv\data_set\foopinmodel.files\20241009_165512\net.nntxt"
	-o "C:\Users\DS1DPC2003M\Desktop\spresense_cv\data_set\foopinmodel.files\20241009_165512"
2024-10-09 16:55:13,386 [nnabla]: [CALLBACK]: Exec train on local
2024-10-09 16:55:13,393 [nnabla]: Using context "Context(backend=['cpu:float'], array_class='CpuCachedArray', device_id='')"
2024-10-09 16:55:13,394 [nnabla]: Creating cache data for "C:\Users\DS1DPC2003M\Desktop\spresense_cv\dataset2\train.csv"
2024-10-09 16:55:13,438 [nnabla]: Creating cache data for "C:\Users\DS1DPC2003M\Desktop\spresense_cv\dataset2\test.csv"
2024-10-09 16:55:13,466 [nnabla]: Train with contexts ['cpu']
2024-10-09 16:55:13,482 [nnabla]: Training epoch 1 of 300 begin
2024-10-09 16:55:13,483 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-10-09 16:55:13,483 [nnabla]: ctx passed to scheduler doesn't have cuda/cudnn backend. lms scheduler will not be used.
2024-10-09 16:55:13,569 [nnabla]: epoch 1 of 300 cost=0.692900  {train_error=0.693455, valid_error=0.698054} time=(0.0s /12.0s) 
2024-10-09 16:55:13,662 [nnabla]: epoch 2 of 300 cost=0.692853  {train_error=0.692919, valid_error=0.696582} time=(0.1s /18.9s) 
2024-10-09 16:55:13,852 [nnabla]: epoch 3 of 300 cost=0.692691  {train_error=0.691956, valid_error=0.697902} time=(0.3s /31.0s) 
2024-10-09 16:55:13,923 [nnabla]: epoch 4 of 300 cost=0.691707  {train_error=0.694138, valid_error=0.697973} time=(0.4s /30.9s) 
2024-10-09 16:55:13,983 [nnabla]: epoch 5 of 300 cost=0.690474  {train_error=0.691391, valid_error=0.698156} time=(0.5s /28.7s) 
2024-10-09 16:55:14,020 [nnabla]: epoch 6 of 300 cost=0.694223  time=(0.5s /26.9s) 
2024-10-09 16:55:14,061 [nnabla]: epoch 7 of 300 cost=0.692310  time=(0.6s /24.8s) 
2024-10-09 16:55:14,100 [nnabla]: epoch 8 of 300 cost=0.694534  time=(0.6s /23.1s) 
2024-10-09 16:55:14,137 [nnabla]: epoch 9 of 300 cost=0.691169  time=(0.7s /21.8s) 
2024-10-09 16:55:14,210 [nnabla]: epoch 10 of 300 cost=0.695097  {train_error=0.694133, valid_error=0.698737} time=(0.7s /20.9s) 
2024-10-09 16:55:14,254 [nnabla]: epoch 11 of 300 cost=0.691320  time=(0.8s /21.0s) 
2024-10-09 16:55:14,296 [nnabla]: epoch 12 of 300 cost=0.690337  time=(0.8s /20.2s) 
2024-10-09 16:55:14,334 [nnabla]: epoch 13 of 300 cost=0.694824  time=(0.8s /19.6s) 
2024-10-09 16:55:14,372 [nnabla]: epoch 14 of 300 cost=0.692810  time=(0.9s /19.0s) 
2024-10-09 16:55:14,408 [nnabla]: epoch 15 of 300 cost=0.690773  time=(0.9s /18.5s) 
2024-10-09 16:55:14,447 [nnabla]: epoch 16 of 300 cost=0.692309  time=(1.0s /18.1s) 
2024-10-09 16:55:14,485 [nnabla]: epoch 17 of 300 cost=0.692726  time=(1.0s /17.7s) 
2024-10-09 16:55:14,523 [nnabla]: epoch 18 of 300 cost=0.693110  time=(1.0s /17.3s) 
2024-10-09 16:55:14,561 [nnabla]: epoch 19 of 300 cost=0.690899  time=(1.1s /17.0s) 
2024-10-09 16:55:14,624 [nnabla]: epoch 20 of 300 cost=0.693670  {train_error=0.693525, valid_error=0.698625} time=(1.1s /16.7s) 
2024-10-09 16:55:14,663 [nnabla]: epoch 21 of 300 cost=0.688044  time=(1.2s /16.9s) 
2024-10-09 16:55:14,702 [nnabla]: epoch 22 of 300 cost=0.694360  time=(1.2s /16.6s) 
2024-10-09 16:55:14,748 [nnabla]: epoch 23 of 300 cost=0.694672  time=(1.3s /16.4s) 
2024-10-09 16:55:14,785 [nnabla]: epoch 24 of 300 cost=0.691007  time=(1.3s /16.3s) 
2024-10-09 16:55:14,823 [nnabla]: epoch 25 of 300 cost=0.690928  time=(1.3s /16.1s) 
2024-10-09 16:55:14,861 [nnabla]: epoch 26 of 300 cost=0.692637  time=(1.4s /15.9s) 
2024-10-09 16:55:14,898 [nnabla]: epoch 27 of 300 cost=0.690328  time=(1.4s /15.7s) 
2024-10-09 16:55:14,936 [nnabla]: epoch 28 of 300 cost=0.695915  time=(1.5s /15.6s) 
